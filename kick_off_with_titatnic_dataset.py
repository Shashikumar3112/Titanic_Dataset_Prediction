# -*- coding: utf-8 -*-
"""Kick Off With Titatnic Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BscgCXDKKFrVDpqHE14-tAar9HBf5typ

# Importing Required Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split

from sklearn.metrics import confusion_matrix, accuracy_score

"""# Data Collection"""

df_train=pd.read_csv("/content/drive/My Drive/PythonBoss/ML Project/titanic_train.csv")
df_test=pd.read_csv("/content/drive/My Drive/PythonBoss/ML Project/test.csv")

"""*   df_train_dataset: For the Model Training
*   df_test_dataset: For the prection with Trained Model

# Exploratory data analysis
To analyzing data sets to summarize their main characteristics, often with visual methods
"""

df_train.info() #To print info abt df_train_dataset
df_train.head(3) #To Print 1st 3 rows of df_train_dataset

df_test.info() #To print info abt df_test_dataset
df_test.head(3) #To Print 1st 3 rows of df_test_dataset

"""## Observation & Action

**Observation**

df_train_dataset has 11 feature & 1 target variable. And df_test_dataset has 10 common features to df_train dataset.

*Unique feature*
* PassengerId: Serial no * Survived : 0=No, 1=Yes

*Categorical features*
* Pclass : 1=1st class,2=2nd,3=3rd
* sex :Male,Female
* Cabin : Unique object & having more Missing value in both dataset
* Ticket :Ticket number
* SibSp : Siblings/Spouces aboard
* Parch :Parents/Chile aboard
* Embarked : Port of Embarkation C=Cherbourg,Q=Queenstown,S=Southampton & 2 missing value found in train dataset

*Numerical fetures*
* Age : Values are missing in both dataset
* Fare : single missing found in test dataset.

**Action**

*feature Engineering*
1. PassengerId:  Remove feature in both dataset
2. sex feature: Change to bool value with Label encoding/ mapping male with 0 & female with 1.
3. Name: extract prefix from name such as Mr,Mrs or etc & map with values or similliarity with prefix.
4. Age: filling missing values,binning/converting numerical age to catgorical variable with values
5. SibSp & Parch:sibsp and parch can be treated together as a family for a passenger. Hence create a feature family:
family=sibsp+parch+1(passenger)
6. Embarked:filling missing values, Label encoding/ mapping 0,1 & 2.
7. Cabin: we will drop or look on entire rows & fill with proper analysis.Cabin name starts with a letter. It may be based on either Pclass or embarked.
8. ticket:unique number so letter will go with analysis
9. fare: fillning missing value...Method 1. Binning/converting numerical age to catgorical variable with values. Method 2.normalization/scaling

### Name: 1.Extracting 2.Mapping 3.Droping
"""

train_test_data=[df_train,df_test]# Combining both so another steps not required for test data
for dataset in train_test_data:
  dataset["title"]=dataset["Name"].str.extract(' ([A-Za-z]+)\.',expand=False)

df_train.title.value_counts()

title_mapping={"Mr":0,"Miss":1,"Mrs":2,"Master":3,"Dr":3,"Rev":3,"Major":3,"Col":3,"Mlle":3,
               "Don":3,"Dona":3,"Mme":3,"Countess":3,"Capt":3,"Ms":3,"Jonkheer":3,"Lady":3,"Sir":3}
for dataset in train_test_data:
  dataset["title"]=dataset["title"].map(title_mapping)

df_train.title.value_counts()

for dataset in train_test_data:
  dataset.drop(["Name"],axis=1, inplace=True)

df_train.head(2)

"""### Sex:1.Label Encoding 2. Dropping"""

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
for dataset in train_test_data:
  dataset["Sex_label"]=le.fit_transform(dataset["Sex"])

df_train.head(1)#male=1, female=0

for dataset in train_test_data:
  dataset.drop(["Sex"],axis=1, inplace=True)

dataset.head(1)

"""### Age"""

df_train.Age.isnull().sum()#check missing value...........177
df_test.Age.isnull().sum()

#pd.pivot_table(df_train,index=["Pclass","title"],aggfunc='mean',values='Age')
dataset.groupby(['Pclass','title'])['Age'].mean()

df_train['Age']=df_train['Age'].fillna(df_train.groupby('title')['Age'].transform("mean"),inplace=False)
df_test['Age']=df_test['Age'].fillna(df_test.groupby('title')['Age'].transform("mean"),inplace=False)

df_train.Age.isnull().sum()
df_test.Age.isnull().sum()

for dataset in train_test_data:
  dataset.loc[dataset['Age']<=16,'Age']=0,
  dataset.loc[(dataset['Age']>16) & (dataset['Age']<=26) ,'Age']=1,
  dataset.loc[(dataset['Age']>26) & (dataset['Age']<=36) ,'Age']=2,
  dataset.loc[(dataset['Age']>36) & (dataset['Age']<=59) ,'Age']=3,
  dataset.loc[dataset['Age']>=60,'Age']=4

"""### Embark"""

df_train.Embarked.isnull().sum()##2
df_test.Embarked.isnull().sum()##0

df_train.loc[df_train['Embarked'].isnull()]#to check entire rows where Nan value found in column

"""Embarked has two missing values. Both are female and from pclass 1. Their ticket fare and cabin numbers are also same. Ticket fare is based on the journey and Pclass. Hence let's find out mean ticket fare for same embarked and same pclass."""

df_train.groupby(['Embarked','Pclass'])['Fare'].median()

"""The person who has embarked from C and Pclass 1 has average fare as 78. Our missing data is also having fare around 80. It shows that both missing embarked are C. Let's fill those values with C."""

df_train['Embarked']=df_train['Embarked'].fillna('C')

sns.countplot(x='Embarked',hue='Survived',data=df_train)

sns.countplot(x='Embarked',hue='Pclass',data=dataset)

"""People who had boarded from C and from Pclass 1, are more survived. Most of the passengers who started from S have booked pclass 3 and died in large number. Embarked has impact on survival. So we will keep it.

### Fare
"""

dataset.Fare.isnull().sum()#Missing value

dataset[dataset['Fare'].isnull()]#to check

"""Only one missing value for fare and that too in test data. Embarked is S and Pclass is 3. Hence fill missing value by 8.05"""

dataset['Fare']=dataset['Fare'].fillna(8.05)

print(len(df_train.loc[df_train['Fare']==0.0]))
print(len(df_test.loc[df_test['Fare']==0.0]))

"""Total 17 passengers have zero fare value and it's rare to have no fare for these many passengers. Hence I am replacing zero by median fare based on pclass and embarked."""

#list of indices where fare=0.
df_train_fare_index_with_0=[df_train.loc[df_train['Fare']==0.0].index] 
for i in df_train_fare_index_with_0:
    df_train.loc[i,'Fare']=df_train.groupby(['Embarked','Pclass'])['Fare'].transform(lambda x : x.median())

df_test_fare_index_with_0=[df_test.loc[df_test['Fare']==0.0].index] 
for i in df_test_fare_index_with_0:
    df_test.loc[i,'Fare']=df_test.groupby(['Embarked','Pclass'])['Fare'].transform(lambda x : x.median())

sns.kdeplot(df_train['Fare'])
#fare plot is right skewed .It is not advisable to use fare directly.Hance will use normalization or scaling technique or binning..my plan to do with binning

for dataset in train_test_data:
  dataset.loc[dataset['Fare']<=15,'Fare']=0,
  dataset.loc[(dataset['Fare']>15) & (dataset['Fare']<=100) ,'Fare']=1,
  dataset.loc[dataset['Fare']>=101,'Fare']=2

df_train.Fare.value_counts()

"""### SibSp & Parch: Fsize"""

df_train["Fsize"] = df_train["SibSp"] + df_train["Parch"]+1
df_test["Fsize"] = df_test["SibSp"] + df_test["Parch"]+1

sns.barplot(x='Fsize',y='Survived',data=df_train)

df_train['Fsize'].value_counts()

for dataset in train_test_data:
  dataset.loc[dataset['Fsize']<=1,'Fsize']=0,
  dataset.loc[(dataset['Fsize']>1) & (dataset['Fsize']<=3) ,'Fsize']=1,
  dataset.loc[dataset['Fsize']>=3,'Fsize']=2

"""### Cabin
Cabin name starts with a letter. It may be based on either Pclass or embarked. Let's first fill missing values of cabin with letter X and extract first letter from cabin.
"""

for dataset in train_test_data:
  dataset['Cabin']=dataset['Cabin'].fillna('X')
  dataset['Cabin']=dataset['Cabin'].str.get(0)

df_train.head()

df_train.Cabin.value_counts()

sns.catplot(x='Cabin',y='Survived',data=df_train,kind='bar')

"""Most of the passengers from X cabin i.e. missing cabin are having lowest survival rate. Let's use one hot encoding and convert this categories into dummy variables in next steps."""

df_train=pd.get_dummies(df_train,columns=["Cabin"],drop_first=True)

df_test=pd.get_dummies(df_test,columns=["Cabin"],drop_first=True)

df_train.head()

"""### Ticket

## Final Check & Preprocessing
"""

df_train.Cabin.value_counts()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
for dataset in train_test_data:
  dataset["Embarked_label"]=le.fit_transform(dataset["Embarked"])

df_train.head()

feature=df_train.drop(["PassengerId","Survived","SibSp","Parch","Cabin_T","Ticket","Embarked"],axis=1)
feature.head(3)

target=df_train.loc[:,["Survived"]]
target.head(3)

log_model=LogisticRegression()
nb_model=GaussianNB()
knn_model=KNeighborsClassifier(n_neighbors=25)
svc_model=SVC()
rf_model=RandomForestClassifier(n_estimators=500,n_jobs=10)

x_train, x_test, y_train, y_test = train_test_split(feature, target,test_size=0.2,random_state=4)

log_model.fit(x_train,y_train)
nb_model.fit(x_train,y_train)
svc_model.fit(x_train,y_train)
knn_model.fit(x_train,y_train)
rf_model.fit(x_train,y_train)

print(log_model.score(x_train,y_train))
print(nb_model.score(x_train,y_train))
print(svc_model.score(x_train,y_train))
print(knn_model.score(x_train,y_train))
print(rf_model.score(x_train,y_train))

print(log_model.score(x_test,y_test))
print(nb_model.score(x_test,y_test))
print(svc_model.score(x_test,y_test))
print(knn_model.score(x_test,y_test))
print(rf_model.score(x_test,y_test))

y_predn=svc_model.predict(x_test)
accuracy_score(y_test,y_predn)

confusion_matrix(y_test,y_predn)

df_test1=df_test.drop(["PassengerId","SibSp","Parch","Ticket","Embarked"],axis=1)
df_test1.head(2)

feature.head(2)

y_predn1=log_model.predict(df_test1)
y_predn2=nb_model.predict(df_test1)
y_predn3=svc_model.predict(df_test1)
y_predn4=knn_model.predict(df_test1)
y_predn5=rf_model.predict(df_test1)

submission1=pd.DataFrame({"PassengerId":df_test["PassengerId"],"Survived":y_predn1})
submission1.to_csv("gender_submission_v1.csv",index=False)

submission2=pd.DataFrame({"PassengerId":df_test["PassengerId"],"Survived":y_predn2})
submission2.to_csv("gender_submission_v2.csv",index=False)

submission3=pd.DataFrame({"PassengerId":df_test["PassengerId"],"Survived":y_predn3})
submission3.to_csv("gender_submission_v3.csv",index=False)

submission5=pd.DataFrame({"PassengerId":df_test["PassengerId"],"Survived":y_predn5})
submission5.to_csv("gender_submission_v5.1.csv",index=False)